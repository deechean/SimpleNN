{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify the gender of the voice\n",
    "\n",
    "7 metrics are: carat,cut,color,clarity,depth,table,size(x,y,z)\n",
    "\n",
    "### Import csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../common/')\n",
    "import csv\n",
    "import random\n",
    "\n",
    "GENDER = {'male':0, 'female':1}\n",
    "class voicegender_data:\n",
    "    def __init__(self,filepath, batch_size=250, shuffle = True):\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle=shuffle\n",
    "        self.data_list, self.label_list = self.load_data(self.read_csv(filepath))\n",
    "        self.batch_index = []\n",
    "        self.index = 0\n",
    "        if self.shuffle:\n",
    "            for i in range(len(self.label_list)):\n",
    "                index = random.randint(0, len(self.label_list)-1)\n",
    "                if not index in self.batch_index:\n",
    "                    self.batch_index.append(index)\n",
    "        else: \n",
    "            for i in range(len(self.label_list)):\n",
    "                self.batch_index.append(i)\n",
    "            print(len(self.batch_index))\n",
    "        \n",
    "    def read_csv(self,filename):\n",
    "        data = []\n",
    "        headline = []\n",
    "        with open(filename, \"r\") as f:\n",
    "            csv_reader = csv.reader(f)\n",
    "            headline = next(csv_reader)\n",
    "            for row in csv_reader:\n",
    "                data.append(row)\n",
    "                #print(row)            \n",
    "        return [headline, data]\n",
    "\n",
    "    def load_data(self, data, shuffle=True):\n",
    "        gender_data = []\n",
    "        gender_label = []\n",
    "        for row in data[1]:\n",
    "            gender_data.append([float(row[0]), float(row[1]),float(row[2]),float(row[3]),float(row[4]),float(row[5]),float(row[6]),\n",
    "                                float(row[7]),float(row[8]),float(row[9]),float(row[10]),float(row[11]),float(row[12]),\n",
    "                                float(row[13]),float(row[14]),float(row[15]),float(row[16]),float(row[17]),float(row[18]),\n",
    "                                float(row[19])])\n",
    "            gender_label.append(GENDER[row[20]])\n",
    "        return gender_data,gender_label\n",
    "\n",
    "    def get_batch_data(self):\n",
    "        batch_data = []\n",
    "        batch_label = []\n",
    "        i = 0\n",
    "        while i < self.batch_size:\n",
    "            batch_data.append(self.data_list[self.batch_index[self.index]])\n",
    "            batch_label.append(self.label_list[self.batch_index[self.index]])\n",
    "            self.index += 1\n",
    "            if self.index >=len(self.batch_index):\n",
    "                self.index = 0\n",
    "            i += 1\n",
    "        return batch_data, batch_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 10)\n",
      "(?, 2)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../common/')\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from train_log import train_log\n",
    "\n",
    "TRAIN_BATCH_SIZE = 1000\n",
    "LEARN_RATE = 0.01\n",
    "\n",
    "\n",
    "log_dir = './log_voicegender/'\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)    \n",
    "log = train_log(log_dir)\n",
    "\n",
    "ckpt_dir = './ckpt_voicegender/'\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)     \n",
    "\n",
    "train_data = voicegender_data('./voicegender_data/voicegender_train.csv', batch_size=TRAIN_BATCH_SIZE)\n",
    "        \n",
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32, [None, 20])\n",
    "    y_ = tf.placeholder(tf.int64, [None])\n",
    "    \n",
    "with tf.name_scope('hidden_layer_1'):\n",
    "    W_1 = tf.Variable(tf.random_uniform([20,10]))\n",
    "    b_1 = tf.Variable(tf.zeros([10]))\n",
    "    node_1 = tf.nn.tanh(tf.matmul(x,W_1)+b_1)\n",
    "    print(node_1.shape)\n",
    "\n",
    "with tf.name_scope('output'):\n",
    "    W_2 = tf.Variable(tf.random_uniform([10,2]))\n",
    "    b_2 = tf.Variable(tf.zeros([2]))\n",
    "    y = tf.nn.softmax(tf.matmul(node_1,W_2)+b_2)\n",
    "    print(y.shape)\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    loss =  tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y,labels=y_,name=\"cross_entropy_per_example\"))\n",
    "\n",
    "with tf.name_scope('train_step'):\n",
    "    train_step = tf.train.GradientDescentOptimizer(LEARN_RATE).minimize(loss)    \n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    prediction =tf.argmax(y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction,y_), tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()  \n",
    "saver = tf.train.Saver(max_to_keep=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./ckpt_voicegender/simpl_nn_ckpt-500000\n",
      "....................................................................................................\n",
      "Step 500999: loss = 0.38， accuracy = 0.94\n",
      "....................................................................................................\n",
      "Step 501999: loss = 0.38， accuracy = 0.93\n",
      "....................................................................................................\n",
      "Step 502999: loss = 0.38， accuracy = 0.93\n",
      "....................................................................................................\n",
      "Step 503999: loss = 0.38， accuracy = 0.93\n",
      "....................................................................................................\n",
      "Step 504999: loss = 0.39， accuracy = 0.92\n",
      "....................................................................................................\n",
      "Step 505999: loss = 0.39， accuracy = 0.93\n",
      "....................................................................................................\n",
      "Step 506999: loss = 0.39， accuracy = 0.93\n",
      "....................................................................................................\n",
      "Step 507999: loss = 0.39， accuracy = 0.92\n",
      "....................................................................................................\n",
      "Step 508999: loss = 0.39， accuracy = 0.92\n",
      "....................................................................................................\n",
      "Step 509999: loss = 0.39， accuracy = 0.92\n",
      "....................................................................................................\n",
      "Step 510999: loss = 0.39， accuracy = 0.92\n",
      "....................................................................................................\n",
      "Step 511999: loss = 0.39， accuracy = 0.92\n",
      "....................................................................................................\n",
      "Step 512999: loss = 0.40， accuracy = 0.92\n",
      "....................................................................................................\n",
      "Step 513999: loss = 0.39， accuracy = 0.92\n",
      "....................................................................................................\n",
      "Step 514999: loss = 0.39， accuracy = 0.92\n",
      "....................................................................................................\n",
      "Step 515999: loss = 0.39， accuracy = 0.93\n",
      "....................................................................................................\n",
      "Step 516999: loss = 0.39， accuracy = 0.93\n",
      "....................................................................................................\n",
      "Step 517999: loss = 0.38， accuracy = 0.93\n",
      "....................................................................................................\n",
      "Step 518999: loss = 0.38， accuracy = 0.93\n",
      "....................................................................................................\n",
      "Step 519999: loss = 0.38， accuracy = 0.93\n",
      "....................................................................................................\n",
      "Step 520999: loss = 0.38， accuracy = 0.94\n",
      "....................................................................................................\n",
      "Step 521999: loss = 0.37， accuracy = 0.94\n",
      "......."
     ]
    }
   ],
   "source": [
    "import time\n",
    "with tf.Session() as sess:      \n",
    "    sess.run(init)\n",
    "    tf.get_default_graph().finalize()\n",
    "    model_file=tf.train.latest_checkpoint(ckpt_dir)\n",
    "    saver.restore(sess,model_file)\n",
    "    for j in range(500000,1000000):\n",
    "        #print(str(j)+ '-1 : '+time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()))\n",
    "        input_data, train_label = train_data.get_batch_data()\n",
    "    \n",
    "        #print(str(j)+ '-2 : '+time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()))\n",
    "        accuracy_val, loss_val, _ = sess.run([accuracy, loss, train_step], \n",
    "                         feed_dict={x: input_data, y_: train_label})\n",
    "        #print(str(j)+ '-3 : '+time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()))\n",
    "        if (j+1) % 10 == 0:\n",
    "            print('.',end='')\n",
    "        if (j+1) % 1000 == 0:\n",
    "            print()\n",
    "            #print(predict)\n",
    "            print('Step %d: loss = %.2f， accuracy = %.2f'%(j,loss_val,accuracy_val))\n",
    "    saver.save(sess,ckpt_dir+'simpl_nn_ckpt',global_step=j+1)\n",
    "    print(\"Training is done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "test_data = voicegender_data('./voicegender_data/voicegender_test.csv', batch_size=1000)\n",
    "\n",
    "with tf.Session() as sess:      \n",
    "    sess.run(init)\n",
    "    tf.get_default_graph().finalize()\n",
    "    model_file=tf.train.latest_checkpoint(ckpt_dir)\n",
    "    saver.restore(sess,model_file)\n",
    "    accuracy_val, loss_val = sess.run([accuracy, loss], \n",
    "                         feed_dict={x: test_data.data_list, y_: test_data.label_list})\n",
    "    print('Test result: loss = %.2f， accuracy = %.2f'%(loss_val,accuracy_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
